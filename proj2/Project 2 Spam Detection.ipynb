{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2 - Spam Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewshan/CIS-678/blob/master/Project%202%20Spam%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV-lPbMo28dk",
        "colab_type": "text"
      },
      "source": [
        "# Imports \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irPzy1lA2JdZ",
        "colab_type": "code",
        "outputId": "66d1ed36-1c1b-439f-ad7e-480270d0e77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import random\n",
        "import nltk.corpus\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\"\"\"\n",
        "  NLTK Set up\n",
        "\"\"\"\n",
        "nltk.download('stopwords')\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d887dQx3MeK",
        "colab_type": "text"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ck97R_3PVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  \"Trains\" our algorithm adding counts of the words of the message into its \n",
        "  corresponding dictionary. (spam_counts or ham_counts)\n",
        "\n",
        "  @param classifcation - The class of the given message\n",
        "  @param msg - The message content\n",
        "\"\"\"\n",
        "def train(classification, msg):\n",
        "  if (classification == \"spam\"):\n",
        "    for word in msg:\n",
        "      if word in spam_counts:\n",
        "        spam_counts[word] += 1\n",
        "      else:\n",
        "        spam_counts[word] = 1\n",
        "  elif (classification == \"ham\"):\n",
        "    for word in msg:\n",
        "      if word in ham_counts:\n",
        "        ham_counts[word] += 1\n",
        "      else:\n",
        "        ham_counts[word] = 1\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Retrieves the word count of the given word if avaliable. If not, returns 0\n",
        "\n",
        "  @param word - The given word\n",
        "  @param dic - The dictionary to read from\n",
        "\n",
        "  @returns - The number of time the word appears of the given dictionary. \n",
        "             Returns 0 if the key does not exists\n",
        "\"\"\"\n",
        "def try_key(word, dic):\n",
        "  try:\n",
        "    return dic[word]\n",
        "  except:\n",
        "    return 0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  This calcuates the P(word | class)\n",
        "  [Probability of the word showing up in the class]\n",
        "\n",
        "  @param - The word\n",
        "  @param - classification of the word\n",
        "  \n",
        "  @returns the probability of P(word | class)\n",
        "\"\"\"\n",
        "def calc_prob(word, classification):\n",
        "  class_list = []\n",
        "  if (classification.lower() == \"spam\"):\n",
        "    class_list = spam_counts\n",
        "  else:\n",
        "    class_list = ham_counts\n",
        "  return (try_key(word, class_list) + 1) / (len(class_list) + len(unique_words))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Calculates whether or not the message is spam or ham \n",
        "  based on previous training data.\n",
        "\n",
        "  @param line - The message given\n",
        "\n",
        "  @returns Spam or Ham based on the model.\n",
        "\"\"\"\n",
        "def calc_class(line):\n",
        "  prob_of_spam = len(spam_training) / (len(spam_training) + len(ham_training))\n",
        "  msg_prob = 1.0\n",
        "  for word in line:\n",
        "    msg_prob *= calc_prob(word, \"spam\")\n",
        "  final_spam_prob = msg_prob * prob_of_spam\n",
        "\n",
        "  prob_of_ham = len(ham_training) / (len(spam_training) + len(ham_training))\n",
        "  msg_prob = 1.0\n",
        "  for word in line:\n",
        "    msg_prob *= calc_prob(word, \"ham\")\n",
        "  final_ham_prob = msg_prob * prob_of_ham\n",
        "\n",
        "  if (final_spam_prob > final_ham_prob):\n",
        "    return \"spam\"\n",
        "  else:\n",
        "    return \"ham\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oitlklpl8fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7GQWjail4Md",
        "colab_type": "text"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_d2Q1ctjhIp",
        "colab_type": "code",
        "outputId": "09a44d5c-130e-4dd3-da24-156ab3ccaf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\"\"\"\n",
        "Variables used for the model\n",
        "\"\"\"\n",
        "# Holds the amount of times a word shows up in the spam training set\n",
        "spam_counts = {} \n",
        "# Holds the amount of times a word shows up in the ham training set\n",
        "ham_counts = {}\n",
        "# The percent of the data that we want in the training set\n",
        "TRAIN_PERCENT = .8\n",
        "# Spam messages for training\n",
        "spam_training = []\n",
        "# Ham messages for training\n",
        "ham_training = []\n",
        "# Spam messages for testing\n",
        "spam_test = []\n",
        "# Ham messages for testing\n",
        "ham_test = []\n",
        "# Set of unique words all all the training data\n",
        "unique_words = set()\n",
        "\n",
        "\"\"\"\n",
        "Read in the data\n",
        "\"\"\"\n",
        "spam_messages = []\n",
        "ham_messages = []\n",
        "file = open(\"textMsgs.data\")\n",
        "for line in file:\n",
        "  temp = line.split('\\t')\n",
        "  classification = temp[0]\n",
        "  message = temp[1].split(\" \")\n",
        "  msg = []\n",
        "  for word in message:\n",
        "    word = word.lower().replace(\",\", \"\").replace(\"'\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"\\\"\", \"\").replace(\"!\", \"\").replace(\"\\n\", \"\")\n",
        "    if len(word) > 2 and word not in stopwords.words('english'):\n",
        "      msg.append(ps.stem(word))\n",
        "\n",
        "  if (classification == \"spam\"):\n",
        "    spam_messages.append(msg)\n",
        "  elif (classification == \"ham\"):\n",
        "    ham_messages.append(msg)\n",
        "spam_count = len(spam_messages)\n",
        "ham_count = len(ham_messages)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Split the data to test and training\n",
        "\"\"\"\n",
        "random.shuffle(spam_messages)\n",
        "random.shuffle(ham_messages)\n",
        "\n",
        "for i in range(int(TRAIN_PERCENT*len(spam_messages))):\n",
        "  spam_training.append(spam_messages[i])\n",
        "\n",
        "for i in range(int(TRAIN_PERCENT*len(spam_messages)), len(spam_messages)):\n",
        "  spam_test.append(spam_messages[i])\n",
        "\n",
        "for i in range(int(TRAIN_PERCENT*len(ham_messages))):\n",
        "  ham_training.append(ham_messages[i])\n",
        "\n",
        "for i in range(int(TRAIN_PERCENT*len(ham_messages)), len(ham_messages)):\n",
        "  ham_test.append(ham_messages[i])\n",
        "\n",
        "print(len(spam_training), \":\", len(spam_test), \"[Spam - Training Data : Test Data]\")\n",
        "print(len(ham_training), \":\", len(ham_test), \"[Ham - Training Data : Test Data]\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Train the model\n",
        "\"\"\"\n",
        "for spam in spam_training:\n",
        "  train(\"spam\", spam)\n",
        "for ham in ham_training:\n",
        "  train(\"ham\", ham)\n",
        "temp = []\n",
        "temp.append(spam_counts.keys())\n",
        "temp.append(ham_counts.keys())\n",
        "for i in spam_counts.keys():\n",
        "  unique_words.add(i)\n",
        "for i in ham_counts.keys():\n",
        "  unique_words.add(i)\n",
        "\n",
        "\"\"\"\n",
        "Test the model\n",
        "\"\"\"\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "for message in spam_test:\n",
        "  prediction = calc_class(message)\n",
        "  if (prediction == \"spam\"):\n",
        "    true_neg += 1\n",
        "  else:\n",
        "    false_pos += 1\n",
        "\n",
        "for message in ham_test:\n",
        "  prediction = calc_class(message)\n",
        "  if (prediction == \"ham\"):\n",
        "    true_pos += 1\n",
        "  else:\n",
        "    false_neg += 1\n",
        "\n",
        "print(\"true_pos: \" + str(true_pos) + \"\\nfalse_pos: \" + str(false_pos) + \"\\ntrue_neg: \" + str(true_neg) + \"\\nfalse_neg: \" + str(false_neg) + \"\\n\")\n",
        "print(\"Percent correct: \" + str((true_pos + true_neg)/(true_pos+true_neg+false_pos+false_neg)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "597 : 150 [Spam - Training Data : Test Data]\n",
            "3861 : 966 [Ham - Training Data : Test Data]\n",
            "true_pos: 964\n",
            "false_pos: 19\n",
            "true_neg: 131\n",
            "false_neg: 2\n",
            "\n",
            "Percent correct: 0.9811827956989247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPNMMgjn30PJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}